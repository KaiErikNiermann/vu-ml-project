\documentclass[12pt,a4paper,oneside]{article}
%\documentclass[12pt,a4paper,oneside,twocolumn]{article}
\usepackage{pagestyle}
\usepackage{codestyle}

% Report hand-in date
\DTMsavedate{date}{2024-03-29}

\title{
    \Huge{Machine Learning} \\ \LARGE 
    Nature's Quest: Deep Learning Exploration of Global Plant Traits from Images and Geodata
}
\author{
Kai E. Niermann \and
Dávid Miklo \and 
Trix Taicet \and
Red Kaláb \and
Conner Dassen
}
\date{\DTMusedate{date}}
\begin{document}
\maketitle

% \lstinputlisting[firstline=10, lastline=13]{code/sample_script.py}

\begin{abstract}
    % Abstract content goes here
\end{abstract}

\section{Introduction}
% primary paragraph 
Global warming and more broadly climate change has become a major concern for the world as its effects are becoming more and more apparent \cite{WANG2023100237}. Changing weather patterns, especially towards more extreme conditions are causing plants to adapt to new environments \cite{GRAY201664}. One method of measuring said adaptation is to look at the traits, that is, properties of a plant that describe how it functions and interacts with the environment. These traits include but are not limited to of the plant height, leaf area, but also dry mass, leaf nitrogen content amongst various others. Monitoring these traits allows us to gain vital insights into how climate change impacts different ecosystems. While somewhat simple manual measurement techniques exist, at scale they are not feasible. This is where Convolutional Neural Networks (CNN) come in.  

\smallskip
Through the work demonstrated by Schiller et al \cite{schiller2021deep} we know that CNNs can be used to predict plant traits from images. The images used to train this network came from \textit{citizen science photographs} which are images taken by citizens of plants from all across the world using AI plant species identification apps (e.g. iNaturalist, Pl@ntNet). Citizen science photographs also come with location metadata, which can be used to extract ancillary geodata such as precipitation, temperature, and soil type. This geodata can optionally be combined with the images to create a CNN which can potentially learn to extract features from images in conjunction with geodata to predict plant traits.

\smallskip
For our method we wanted to compare the accuracy of a CNN trained on images alone and using a pretrained backbone (e.g. ResNet, EfficientNet, etc.) to a CNN trained on images and geodata. We hypothesize that the CNN trained on images and geodata will outperform the CNN trained on images alone. Although the geodata could potentially lead the model to learning features not necessarily helpful for accurate prediction of plant traits due to a multitiude of reasons. 


% secondary paragraph
\section{Literature review}

\section{Method}

The key 
\subsection{Data processing}

\subsection{Model design}

\subsection{Model evaluation}

\section{Results}

\section{Discussion}

\section{Conclusion}

\printbibliography

\end{document}