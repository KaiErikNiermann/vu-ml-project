{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports \n",
    "Necessary imports, based in part on [this](https://www.kaggle.com/code/awsaf49/planttraits2024-kerascv-starter-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # you can also use tensorflow or torch\n",
    "\n",
    "# deep learning\n",
    "import keras_cv\n",
    "import keras\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# stats\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "# misc \n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "The general format of each instance of the data is \n",
    "```\n",
    "[ids*, ancillary data*, trait means*, traits sd*, image path]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "DATA_PATH = \"../data\"\n",
    "\n",
    "# creating df that has image path and related ancillary data\n",
    "df = pd.read_csv(DATA_PATH + \"/train.csv\")\n",
    "df['image_path'] = f'{DATA_PATH}/train_images/' + df['id'].astype(str) + '.jpeg'\n",
    "df.loc[:, config.aux_class_names] = df.loc[:, config.aux_class_names].fillna(-1)\n",
    "display(df.head(2))\n",
    "print(df.shape[0]) \n",
    "\n",
    "# same df but for the test data\n",
    "test_df = pd.read_csv(DATA_PATH + \"/test.csv\")\n",
    "test_df['image_path'] = f'{DATA_PATH}/test_images'+ test_df['id'].astype(str) + '.jpeg'\n",
    "FEATURE_COLS = list(test_df.columns[1:-1])\n",
    "display(test_df.head(2))\n",
    "print(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_traits = df.iloc[:, 164:170]\n",
    "sd_traits = df.iloc[:, 170:176]\n",
    "display(mean_traits.head(2))\n",
    "\n",
    "\n",
    "def mean_normalizer(col):\n",
    "    mean = mean_traits.iloc[:, col]\n",
    "    mean = mean.drop_duplicates()\n",
    "    return (mean - mean.min()) / (mean.max() - mean.min())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(6): \n",
    "    plt.hist(mean_normalizer(i), log=True, bins=100, alpha=0.5, label=f'Normalized x{i} mean')\n",
    "    \n",
    "plt.title('Normalized mean trait distributions')\n",
    "plt.xlabel('Normalized mean trait value')\n",
    "plt.ylabel('Log count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_11_mean = mean_traits.iloc[:, 1]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# remove outliers\n",
    "x_11_mean = x_11_mean[x_11_mean.between(x_11_mean.quantile(0), x_11_mean.quantile(1))]\n",
    "\n",
    "x_11_mean = x_11_mean.drop_duplicates()\n",
    "\n",
    "ax[0].hist(x_11_mean, bins=100, log=True, alpha=0.5)\n",
    "ax[0].set_title('x11 mean distribution')\n",
    "ax[0].set_xlabel('x11 mean value')\n",
    "ax[0].set_ylabel('Log count')\n",
    "\n",
    "x_11_mean = x_11_mean[x_11_mean.between(x_11_mean.quantile(0), x_11_mean.quantile(0.99))]\n",
    "print(x_11_mean.count())\n",
    "ax[1].hist(x_11_mean, bins=100, alpha=0.5)\n",
    "ax[1].set_title('x11 mean distribution (99th percentile)')\n",
    "ax[1].set_xlabel('x11 mean value')\n",
    "ax[1].set_ylabel('Instance count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 6, figsize=(30, 5))\n",
    "\n",
    "for i in range(6):\n",
    "    x_mean = mean_traits.iloc[:, i]\n",
    "    x_mean = x_mean[x_mean.between(x_mean.quantile(0), x_mean.quantile(0.99))]\n",
    "    x_mean = x_mean.drop_duplicates()\n",
    "    \n",
    "    ax[i].hist(x_mean, bins=100, log=True, alpha=0.5, label=f'Normalized x{i} mean')\n",
    "    ax[i].set_title(f'x{i} mean distribution (99th percentile)')\n",
    "    ax[i].set_xlabel(f'x{i} mean value')\n",
    "    ax[i].set_ylabel('Log count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us some idea of the distribution of the targets we are training for. One thing to consider is that this distribution of traits might not be representative of the general traits of plant species. \n",
    "*Notes*\n",
    "- we can maybe check some location data to see where most of the images came from to see if certain traits indicate a geographic bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sd traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_traits = df.iloc[:, 170:176]\n",
    "display(sd_traits.head(2))\n",
    "def sd_normalizer(col):\n",
    "    sd = sd_traits.iloc[:, col]\n",
    "    return (sd - sd.min()) / (sd.max() - sd.min())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(6):  \n",
    "    plt.hist(sd_normalizer(i), log=True, bins=100, alpha=0.5, label=f'Normalized SD x{i}')\n",
    "\n",
    "plt.title('Normalized standard deviation trait distributions')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be an even better representative that we are training towards a biased sample. Intuitively I'd assume that traits would probably have a large variance if we have a geographic diversity in our sample, but here it seems this is less so the case for most of the deviations maybe ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ancillary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancillary_data = df.iloc[:, 1:164]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# worldclim \n",
    "worldclim = ancillary_data.filter(like='WORLDCLIM')\n",
    "\n",
    "g = sns.pairplot(worldclim, diag_kind='kde', plot_kws={'alpha': 0.5})\n",
    "\n",
    "# remove labels \n",
    "for ax in g.axes.flatten():\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldclim = ancillary_data.filter(like='WORLDCLIM')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "corr = worldclim.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', cbar=True)\n",
    "ax.set_title('Worldclim feature correlation heatmap')\n",
    "\n",
    "high_corr = [i for i in corr[corr > 0.9].stack().index.tolist() if i[0] != i[1]]\n",
    "high_corr = list(set([tuple(sorted(i)) for i in high_corr]))\n",
    "\n",
    "scaled_worldclim_data = (worldclim - worldclim.min()) / (worldclim.max() - worldclim.min())\n",
    "print(high_corr)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca_result = pca.fit_transform(scaled_worldclim_data)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot PCA\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(pca_result[:, 0], pca_result[:, 1], pca_result[:, 2], c=pca_result[:, 0], cmap='viridis', s=10)\n",
    "ax1.set_title('PCA of worldclim features')\n",
    "\n",
    "reconstructed_pca = pca.inverse_transform(pca_result)\n",
    "loss_pca = np.mean((scaled_worldclim_data - reconstructed_pca) ** 2)\n",
    "\n",
    "print(f'PCA Reconstruction Loss: {loss_pca}')\n",
    "\n",
    "# UMAP\n",
    "reducer = umap.UMAP(n_components=3)\n",
    "embedding = reducer.fit_transform(scaled_worldclim_data)\n",
    "\n",
    "# Plot UMAP\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2], c=embedding[:, 0], cmap='viridis', s=10)\n",
    "ax2.set_title('UMAP embedding of worldclim features')\n",
    "\n",
    "reconstructed_umap = reducer.inverse_transform(embedding)\n",
    "loss_umap = np.mean((scaled_worldclim_data - reconstructed_umap) ** 2)\n",
    "\n",
    "print(f'UMAP Reconstruction Loss: {loss_umap}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we start of by just looking at worldclim subset of our training data and testing out some of the basic methods we are going to then use on the broader dataset, namely finding correlations and then comparing the performance of PCA vs UAMP in the dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancillary_data = df.iloc[:, 1:164]\n",
    " \n",
    "worldclim   = ancillary_data.filter(like='WORLDCLIM')\n",
    "soil        = ancillary_data.filter(like='SOIL')\n",
    "modis       = ancillary_data.filter(like='MODIS')\n",
    "vod         = ancillary_data.filter(like='VOD')\n",
    "\n",
    "print(\n",
    "    f\"lengths {len(worldclim.columns)}, {len(soil.columns)}, {len(modis.columns)}, {len(vod.columns)}\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 x 1 subplot of correlation heatmaps \n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# soil \n",
    "\n",
    "soil_corr = soil.corr()\n",
    "sns.heatmap(soil_corr, ax=ax[0], cmap='coolwarm', annot=False)\n",
    "\n",
    "ax[0].set_title('Soil feature correlation heatmap')\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_yticklabels([])\n",
    "ax[0].set_xlabel(\"Feature index\")\n",
    "ax[0].set_ylabel(\"Feature index\")\n",
    "\n",
    "# modis\n",
    "\n",
    "modis_corr = modis.corr()\n",
    "sns.heatmap(modis_corr, ax=ax[1], cmap='coolwarm', annot=False)\n",
    "\n",
    "ax[1].set_title('MODIS feature correlation heatmap')\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_xlabel(\"Feature index\")\n",
    "ax[1].set_ylabel(\"Feature index\")\n",
    "\n",
    "# vod\n",
    "\n",
    "vod_corr = vod.corr()\n",
    "sns.heatmap(vod_corr, ax=ax[2], cmap='coolwarm', annot=False)\n",
    "\n",
    "ax[2].set_title('VOD feature correlation heatmap')\n",
    "ax[2].set_xticklabels([])\n",
    "ax[2].set_yticklabels([])\n",
    "ax[2].set_xlabel(\"Feature index\")\n",
    "ax[2].set_ylabel(\"Feature index\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = [worldclim.corr(), soil.corr(), modis.corr(), vod.corr()]\n",
    "\n",
    "high_corr = [] \n",
    "\n",
    "for corr in correlations:\n",
    "    high_corr += [\n",
    "        i for i in corr[corr > 0.9].stack().index.tolist() if i[0] != i[1]\n",
    "    ]\n",
    "    \n",
    "mod_corr = []\n",
    "\n",
    "for corr in correlations:\n",
    "    mod_corr += [\n",
    "        i for i in corr[corr > 0.65].stack().index.tolist() if i[0] != i[1]\n",
    "    ]\n",
    "    \n",
    "total_cols = 164 \n",
    "all_comb_num = total_cols * (total_cols - 1) / 2\n",
    "    \n",
    "high_corr = list(set([tuple(sorted(i)) for i in high_corr]))\n",
    "print(\n",
    "    f'num combinations with high correlation: {len(high_corr)}' + \n",
    "    f' ({len(high_corr) / all_comb_num * 100:.2f}%)' +\n",
    "    f' tot = {all_comb_num}' \n",
    ")\n",
    "print(\n",
    "    f'num combinations with moderate correlation: {len(mod_corr)}' +\n",
    "    f' ({len(mod_corr) / all_comb_num * 100:.2f}%)' +\n",
    "    f' tot = {all_comb_num}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ancillary_data = df.iloc[:, 1:164]\n",
    "\n",
    "# random sample of ancillary data subset \n",
    "ancillary_data = scaler.fit_transform(ancillary_data)\n",
    "\n",
    "# PCA \n",
    "pca = PCA(n_components=0.95)\n",
    "pca_result = pca.fit_transform(ancillary_data)\n",
    "\n",
    "# UMAP\n",
    "reducer = umap.UMAP(n_components=30)\n",
    "embedding = reducer.fit_transform(ancillary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter over all rows in df and look for missing data\n",
    "\n",
    "bad_rows = []\n",
    "incomplete_cols = [n for n in config.aux_class_names if n.startswith(\"X\") and n.endswith(\"_sd\")]  # there is some missing data in the X*_sd columns\n",
    "for i, row in df.iterrows():\n",
    "    # check if any of those is a 0, -1 or 1\n",
    "    if row[incomplete_cols].isin([0, -1, 1]).any():\n",
    "        bad_rows.append(i)\n",
    "        # replace them with nans instead\n",
    "        df.loc[i, incomplete_cols] = np.nan\n",
    "\n",
    "# remove duplicates\n",
    "bad_rows = set(bad_rows)\n",
    "percentage_bad = len(bad_rows) / len(df) * 100\n",
    "print(f\"Found {len(bad_rows)} bad rows ({len(bad_rows)}/{len(df)}) ({percentage_bad:.2f}%)\")\n",
    "\n",
    "# display top 5 bad rows\n",
    "missing_data_df = df.iloc[list(bad_rows)]\n",
    "missing_data_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where ?\n",
    "\n",
    "Features marked as `X*_sd` are missing for almost 30% of the data (16387/55489) (29.53%). The rest of the data seems to be complete, with no other missing/zeroed values. We can ignore these rows, or we can simply ignore those features as it is a significant amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN to try to fill the X*_sd columns\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, missing_values=-1.0, weights='distance')\n",
    "\n",
    "tabular = df.iloc[:, 170:176]\n",
    "\n",
    "imputed_df = None\n",
    "\n",
    "# if data not in csv already \n",
    "if not os.path.exists(f\"{DATA_PATH}/train_knn_imputed.csv\"):\n",
    "    imputed_tabluar = imputer.fit_transform(tabular)\n",
    "    imputed_df = pd.DataFrame(imputed_tabluar)\n",
    "else: \n",
    "    imputed_df = pd.read_csv(f\"{DATA_PATH}/train_knn_imputed.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tabular.head(5))\n",
    "\n",
    "df = pd.concat([df.iloc[:, :170], tabular, df['image_path']], axis=1)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = imputed_df.rename(columns={i: f\"{config.aux_class_names[i]}\" for i in range(6)})\n",
    "\n",
    "# save the imputed data to a new csv in 'data/test_knn_imputed.csv'\n",
    "if not os.path.exists(f\"{DATA_PATH}/train_knn_imputed.csv\"):\n",
    "    df = pd.concat([df.iloc[:, :170], imputed_df, df['image_path']], axis=1)\n",
    "    df.to_csv(DATA_PATH + '/train_knn_imputed.csv', index=False)\n",
    "\n",
    "df = imputed_df.copy()\n",
    "\n",
    "train_df = df.copy()\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_viewer(df):\n",
    "    # slice the df to only include the columns we want\n",
    "    img_df = df[[\"image_path\"] + config.class_names]\n",
    "# sample 5 rows \n",
    "    img_df = img_df.sample(5)\n",
    "\n",
    "    img, traits = list(img_df[\"image_path\"].values), list(img_df[config.class_names].values)\n",
    "\n",
    "    num_imgs, num_cols = 5, 5\n",
    "\n",
    "    plt.figure(figsize=(5 * num_cols, num_imgs // num_cols * 5))\n",
    "    for i, (img, traits) in enumerate(zip(img, traits)):\n",
    "        plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        formatted_tar = \"\\n\".join(\n",
    "        [\n",
    "            \", \".join(\n",
    "                f\"{name.replace('_mean','')}: {val:.2f}\"\n",
    "                for name, val in zip(config.class_names[j : j + 3], traits[j : j + 3])\n",
    "            )\n",
    "            for j in range(0, len(config.class_names), 3)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"[{formatted_tar}]\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "test_image_viewer(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=config.num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create separate bin for each traits\n",
    "for i, trait in enumerate(config.class_names):\n",
    "    bin_edges = np.percentile(df[trait], np.linspace(0, 100, config.num_folds + 1))\n",
    "    df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
    "\n",
    "df[\"final_bin\"] = (\n",
    "    df[[f\"bin_{i}\" for i in range(len(config.class_names))]]\n",
    "    .astype(str)\n",
    "    .agg(\"\".join, axis=1)\n",
    ")\n",
    "\n",
    "# Perform the stratified split using final bin\n",
    "df = df.reset_index(drop=True)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n",
    "    df.loc[valid_idx, \"fold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 6, figsize=(30, 5))\n",
    "\n",
    "display(df.head(2))\n",
    "\n",
    "avg_hist = {i: [] for i in range(6)}\n",
    "\n",
    "for j in range(5):\n",
    "    for i in range(6):\n",
    "        fold_n = df[df[\"fold\"] == j]\n",
    "        plt_df = fold_n[config.class_names[i]]\n",
    "        \n",
    "        plt_df = plt_df[plt_df.between(plt_df.quantile(0), plt_df.quantile(0.99))]\n",
    "        \n",
    "        avg_hist[i].append(plt_df)\n",
    "        plt_df = (plt_df - plt_df.min()) / (plt_df.max() - plt_df.min())\n",
    "        \n",
    "        ax[i].hist(plt_df, bins=100, log=True, alpha=0.5, label=f\"Fold {j} {config.class_names[i]}\")\n",
    "        ax[i].set_title(config.class_names[i])\n",
    "        ax[i].set_xlabel(f\"{config.class_names[i]} value\")\n",
    "        ax[i].set_ylabel(\"Log count\")\n",
    "        ax[i].legend()\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool ok so we know that visually the traits are equally distributed in the different folds, so that confirms that, now it might make sense to like quantifably check this. We can I think just average the histograms then compare the distance (I think its called?) with that of the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "print(list(avg_hist.values())[0][1].shape)\n",
    "x4 = list(avg_hist.values())[0][1]\n",
    "# print nan in x4\n",
    "series_list = list(avg_hist.values())\n",
    "\n",
    "series_list = list(map(lambda x: pd.DataFrame(x).sum(axis=0) / 5, series_list))\n",
    "\n",
    "for i in range(6):\n",
    "    print(series_list[i].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_traits = df.iloc[:, 164:170]\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(30, 5))\n",
    "\n",
    "for i, (x_mean_col, avrg_mean) in enumerate(zip(mean_traits.columns, series_list)):\n",
    "    x_mean = mean_traits[x_mean_col]\n",
    "    x_mean = x_mean[x_mean.between(x_mean.quantile(0), x_mean.quantile(0.99))]\n",
    "    x_mean = (x_mean - x_mean.min()) / (x_mean.max() - x_mean.min())\n",
    "\n",
    "    avrg_mean = avrg_mean[:54934]\n",
    "\n",
    "    # TODO - maybe use something better than wasserstein distance to eval the distributions\n",
    "    print(f\"Distribution difference for {config.class_names[i]}: {wasserstein_distance(x_mean, avrg_mean)}\")\n",
    "\n",
    "    avrg_mean = (avrg_mean - avrg_mean.min()) / (avrg_mean.max() - avrg_mean.min())\n",
    "    ax[i].hist(x_mean, bins=100, log=True, alpha=0.5, label=f\"Normalized {config.class_names[i]} mean\")\n",
    "    ax[i].hist(avrg_mean, bins=100, log=True, alpha=0.4, label=f\"Averaged {config.class_names[i]} mean (5 folds)\")\n",
    "    ax[i].set_title(f\"x{i} mean distribution (99th percentile)\")\n",
    "    ax[i].set_xlabel(f\"x{i} mean value\")\n",
    "    ax[i].set_ylabel(\"Log count\")\n",
    "    ax[i].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from databuilder import build_dataset\n",
    "\n",
    "# Sample from full data\n",
    "sample_df = df.copy()\n",
    "train_df = sample_df[sample_df.fold != config.fold]\n",
    "valid_df = sample_df[sample_df.fold == config.fold]\n",
    "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_df[FEATURE_COLS].values)\n",
    "valid_features = scaler.transform(valid_df[FEATURE_COLS].values)\n",
    "\n",
    "# Train | img + geo\n",
    "train_paths = train_df.image_path.values\n",
    "train_labels = train_df[config.class_names].values\n",
    "train_aux_labels = train_df[config.aux_class_names].values\n",
    "train_ds_ig = build_dataset(train_paths, train_features, train_labels, train_aux_labels,\n",
    "                         batch_size=config.batch_size, cache_dir=f\"{DATA_PATH}/cached_training\",\n",
    "                         repeat=True, shuffle=True, augment=True, cache=False)\n",
    "\n",
    "# Valid | img + geo\n",
    "valid_paths = valid_df.image_path.values\n",
    "valid_labels = valid_df[config.class_names].values\n",
    "valid_aux_labels = valid_df[config.aux_class_names].values\n",
    "valid_ds = build_dataset(valid_paths, valid_features, valid_labels, valid_aux_labels,\n",
    "                         batch_size=config.batch_size, cache_dir=f\"{DATA_PATH}/cached_training\",\n",
    "                         repeat=False, shuffle=False, augment=False, cache=False)\n",
    "\n",
    "# Train | img\n",
    "train_ds_i = build_dataset(train_paths, None,train_labels, train_aux_labels,\n",
    "                         batch_size=config.batch_size, cache_dir=f\"{DATA_PATH}/cached_training\",\n",
    "                         repeat=True, shuffle=True, augment=True, cache=False)\n",
    "\n",
    "# Valid | img\n",
    "valid_ds_i = build_dataset(valid_paths, None, valid_labels, valid_aux_labels,\n",
    "                         batch_size=config.batch_size, cache_dir=f\"{DATA_PATH}/cached_training\",\n",
    "                         repeat=False, shuffle=False, augment=False, cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for model\n",
    "from loss import R2Loss, R2Metric, adjusted_R2Loss\n",
    "\n",
    "# testing r2\n",
    "y_true = np.array([1, 2, 3, 4, 5])\n",
    "y_pred = np.array([1, 1, 3, 4, 5])\n",
    "\n",
    "r2 = R2Metric()\n",
    "r2.update_state(y_true, y_pred)\n",
    "print(r2.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import *\n",
    "from config import config\n",
    "from model import Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backbone comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing differen backbones\n",
    "nn1 = Model(config, \"efficientnetv2_b2_imagenet\")\n",
    "nn2 = Model(config, \"resnet50_imagenet\")\n",
    "nn3 = Model(config, \"efficientnetv2_s_imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 x 3 keras model plot \n",
    "fig, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "# TODO - causes errors\n",
    "plot_model(nn1, to_file='model_nn1.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(nn2, to_file='model_nn2.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(nn3, to_file='model_nn3.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Load and display the images\n",
    "img1 = plt.imread('model_nn1.png')\n",
    "img2 = plt.imread('model_nn2.png')\n",
    "img3 = plt.imread('model_nn3.png')\n",
    "\n",
    "# Delete the images after loading them\n",
    "os.remove('model_nn1.png')\n",
    "os.remove('model_nn2.png')\n",
    "os.remove('model_nn3.png')\n",
    "\n",
    "ax[0].imshow(img1)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Model 1')\n",
    "\n",
    "ax[1].imshow(img2)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Model 2')\n",
    "\n",
    "ax[2].imshow(img3)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('Model 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 5e-5, 8e-6 * batch_size, 1e-5\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # Plot lr curve if plot is True\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('LR Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False) \n",
    "\n",
    "lr_cb = get_lr_callback(config.batch_size, mode=config.lr_mode, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps, tars = next(iter(train_ds_i))\n",
    "imgs = inps[\"images\"]\n",
    "num_imgs, num_cols = 5, 5\n",
    "\n",
    "plt.figure(figsize=(5 * num_cols, num_imgs // num_cols * 5))\n",
    "for i, (img, tar) in enumerate(zip(imgs[:num_imgs], tars[0][:num_imgs])):\n",
    "    plt.subplot(num_imgs // num_cols, num_cols, i + 1)\n",
    "    img = img. numpy()\n",
    "    tar = tar.numpy()\n",
    "    \n",
    "    img = (img - img.min()) / (img.max() + 1e-4)\n",
    "\n",
    "    formatted_tar = \"\\n\".join(\n",
    "        [\n",
    "            \", \".join(\n",
    "                f\"{name.replace('_mean','')}: {val:.2f}\"\n",
    "                for name, val in zip(config.class_names[j : j + 3], tar[j : j + 3])\n",
    "            )\n",
    "            for j in range(0, len(config.class_names), 3)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"[{formatted_tar}]\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "histories = []\n",
    "\n",
    "# make dir ../data/weights\n",
    "if not os.path.exists(\"../data/weights\"):\n",
    "    os.makedirs(\"../data/weights\")\n",
    "    \n",
    "# make history dir \n",
    "if not os.path.exists(\"../data/history\"):\n",
    "    os.makedirs(\"../data/history\")\n",
    "\n",
    "for network in [nn1, nn2, nn3]:\n",
    "    print(f\"started training {network}\")\n",
    "    \n",
    "    if os.path.exists(f\"../data/weights/{network.name}.keras\"):\n",
    "        print(f\"weights for {network.name} already exist, skipping training\")\n",
    "        continue\n",
    "    \n",
    "    ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "        f\"../data/weights/{network.name}.keras\",\n",
    "        monitor=\"val_head_r2\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "    )\n",
    "    \n",
    "    history = network.fit(\n",
    "        train_ds_i,\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[lr_cb, ckpt_cb],\n",
    "        steps_per_epoch=len(train_df) // config.batch_size,\n",
    "        validation_data=valid_ds_i,\n",
    "        verbose=config.verbose,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    histories.append((history.history, ckpt_cb))\n",
    "    # pickle dump history.history \n",
    "    with open(f\"../data/history/{network.name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history.history as ../data/functional_1.pkl\n",
    "histories = []\n",
    "for i in os.listdir(\"../data/history/old1\"):\n",
    "    with open(f\"../data/history/old1/{i}\", \"rb\") as f:\n",
    "        histories.append(pickle.load(f))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(30, 5))\n",
    "\n",
    "for idx, i in enumerate(histories):\n",
    "    best_R2 = max(i['val_head_r2'])\n",
    "    best_Epoch = np.argmax(i['val_head_r2']) + 1\n",
    "    print(\"#\" * 10 + \" Result \" + \"#\" * 10)\n",
    "    print(f\"Best R2: {best_R2:.5f}\")\n",
    "    print(f\"Best Epoch: {best_Epoch}\")\n",
    "    print(\"#\" * 28)\n",
    "    \n",
    "    ax[idx].plot(i['loss'], label='train r2')\n",
    "    ax[idx].plot(i['val_loss'], label='val r2')\n",
    "    ax[idx].set_xlabel('Epoch')\n",
    "    ax[idx].set_ylabel('R2')\n",
    "    ax[idx].set_title(f\"{list(histories[idx].keys())[0]}\")\n",
    "    ax[idx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "history = None \n",
    "with open(\"../data/history/functional_7.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "    \n",
    "print(history)\n",
    "    \n",
    "# plot 'head_accuracy' \n",
    "plt.plot(history['head_accuracy'], label='train accuracy', log=True)\n",
    "plt.plot(history['val_head_accuracy'], label='val accuracy', log=True)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluting model and tuning hyperparameters\n",
    "\n",
    "# training, validation acc \n",
    "\n",
    "# training, validation loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline for the ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation + tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating ensemble model and tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble vs image model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion \n",
    "\n",
    "( you can use any notes here in the paper )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
